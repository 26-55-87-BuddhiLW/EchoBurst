Model Files on Media Fire

Instructions: Unzip the files and place them in a folder called Models. This folder should be located in the same folder as the core code. 

All models: The three main models used so far
[Link](https://www.mediafire.com/folder/mz7u83r5ivs8j/Models)

miniCorpus: A selection of about 2 gb of comments from Feb 2017. Has been the most used and useful model so far, as it's smaller and faster to load, while still appearing to have decent accuracy. Was iterated over approximately 50 times. 
[Link](http://www.mediafire.com/file/i0e4cmdzxq08zcm/miniCorpus.7z) 

clusteredCorpus: The miniCorpus, but with the addition of a cluster tag, as well as a subreddit tag. Cluster tags were created using KMeans (num_clusters 40), and seem to have some semantic coherence. This is done just to make classification more viable, as 40 classes are far easier to work with than the 38k subreddits. This will be the corpus that is experimented on in order to figure out the best implementation for classification ahead of the creation of the final corpus. Iterated over about 20 times, could be improved with retraining. 
[Link](http://www.mediafire.com/file/s0zoiuifqu4l8eh/clusteredCorpus.7z)


fullCorpus: The model based off of every comment during February of 2017. Very large and slow, but probably the most accurate. However it's rarely used, as it's not very similar to the smaller model we'll be forced to build as our final corpus. Iterated over 25 times. Retraining possible, but very slow. 
[Link](http://www.mediafire.com/file/dfyvkkc8qh4vyrg/fullCorpus.7z)
